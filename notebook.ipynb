{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.mapping import production_mapping\n",
    "\n",
    "def download_raw_file():\n",
    "    url = \"https://ir.eia.gov/wpsr/psw09.xls\"\n",
    "    response = requests.get(url)\n",
    "    # Save the file to the specified directory\n",
    "    file_path = \"./data/eia_weekly_psw09.xls\"\n",
    "    with open(file_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "def read_excel_file():\n",
    "    file_path = './data/eia_weekly_psw09.xls'\n",
    "    sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "    contents = sheets.pop('Contents')\n",
    "    return sheets\n",
    "\n",
    "def parse_data(df):\n",
    "    df = df.copy()\n",
    "    df.columns = df.iloc[0] + '___' + df.iloc[1]\n",
    "    df = df.drop([0, 1])\n",
    "    df = df.rename(columns={df.columns[0]: 'period'})\n",
    "    df['period'] = pd.to_datetime(df['period'])\n",
    "    df = df[df['period'] >= '2014-12-19']\n",
    "    df = df.melt(id_vars=['period'], var_name='id', value_name='value')\n",
    "    df[['id', 'name']] = df['id'].str.split('___', expand=True)\n",
    "    return df\n",
    "\n",
    "def parse_all_data(sheets):\n",
    "    df = pd.DataFrame()\n",
    "    for sheet in sheets:\n",
    "        df = pd.concat([df, parse_data(sheets[sheet])])\n",
    "    #remove duplicate in period and id\n",
    "    df = df.drop_duplicates(subset=['period', 'id'])\n",
    "    return df\n",
    "\n",
    "def generate_additional_calculation(df):\n",
    "    df = df.copy()\n",
    "    crudeRuns = ['WCRRIUS2','WCRRIP12','WCRRIP22','WCRRIP32','WCRRIP42','WCRRIP52',]\n",
    "    grossRuns = ['WGIRIUS2','WGIRIP12','WGIRIP22','WGIRIP32','WGIRIP42','WGIRIP52',]    \n",
    "    crudeStocks = ['WCESTUS1','WCESTP11','WCESTP21','WCESTP31','WCESTP41','WCESTP51','W_EPC0_SAX_YCUOK_MBBL']    \n",
    "    crudeImports = ['WCEIMUS2','WCEIMP12','WCEIMP22','WCEIMP32','WCEIMP42','WCEIMP52',]\n",
    "    # crudeOriginalAdjustment = ['WCRAUUS2','W_EPC0_TVP_NUS_MBBLD']\n",
    "    \n",
    "    # idsToInclude = crudeRuns + grossRuns + crudeStocks + crudeImports + crudeOriginalAdjustment\n",
    "    idsToInclude = crudeRuns + grossRuns + crudeStocks + crudeImports\n",
    "\n",
    "    df = df[df['id'].isin(idsToInclude)]\n",
    "\n",
    "    df = df.pivot(index='period',columns='id',values='value')\n",
    "    \n",
    "    #Feedstock Inputs into Refineries\n",
    "    df['feedstockRunsUS'] = df['WGIRIUS2'] - df['WCRRIUS2']\n",
    "    df['feddStockRunsP1'] = df['WGIRIP12'] - df['WCRRIP12']\n",
    "    df['feedstockRunsP2'] = df['WGIRIP22'] - df['WCRRIP22']\n",
    "    df['feedstockRunsP3'] = df['WGIRIP32'] - df['WCRRIP32']\n",
    "    df['feedstockRunsP4'] = df['WGIRIP42'] - df['WCRRIP42']\n",
    "    df['feedstockRunsP5'] = df['WGIRIP52'] - df['WCRRIP52']\n",
    "    \n",
    "    #P9 Crude Runs\n",
    "    df['crudeRunsP9'] = df['WCRRIP22'] + df['WCRRIP32'] + df['WCRRIP42']\n",
    "    #P9 Gross Runs\n",
    "    df['grossRunsP9'] = df['WGIRIP22'] + df['WGIRIP32'] + df['WGIRIP42']\n",
    "    #P9 Feedstock Runs\n",
    "    df['feedstockRunsP9'] = df['grossRunsP9'] - df['crudeRunsP9']\n",
    "    #P9 Crude Stocks\n",
    "    df['crudeStocksP9'] = df['WCESTP21'] + df['WCESTP31'] + df['WCESTP41']\n",
    "    #P9 Crude Imports\n",
    "    df['crudeImportsP9'] = df['WCEIMP22'] + df['WCEIMP32'] + df['WCEIMP42']\n",
    "    #P9 Crude Original Adjustment\n",
    "    # df['crudeOriginalAdjustment'] = df['WCRAUUS2'] + df['W_EPC0_TVP_NUS_MBBLD']\n",
    "    #P2E crudeStocksP2E\n",
    "    df['crudeStocksP2E'] = df['WCESTP21'] - df['W_EPC0_SAX_YCUOK_MBBL']    \n",
    "\n",
    "    wps_dicts = {\n",
    "        'feedstockRunsUS' : 'Weekly U.S. Feedstock Inputs into Refineries  (Thousand Barrels per Day)',\n",
    "        'feddStockRunsP1' : 'Weekly East Coast (PADD 1) Feedstock Inputs into Refineries  (Thousand Barrels per Day)',\n",
    "        'feedstockRunsP2' : 'Weekly Midwest (PADD 2) Feedstock Inputs into Refineries  (Thousand Barrels per Day)',\n",
    "        'feedstockRunsP3' : 'Weekly Gulf Coast (PADD 3) Feedstock Inputs into Refineries  (Thousand Barrels per Day)',\n",
    "        'feedstockRunsP4' : 'Weekly Rocky Mountain (PADD 4) Feedstock Inputs into Refineries  (Thousand Barrels per Day)',\n",
    "        'feedstockRunsP5' : 'Weekly West Coast (PADD 5) Feedstock Inputs into Refineries  (Thousand Barrels per Day)',\n",
    "        'crudeRunsP9' : 'Weekly PADD 9 Crude Runs  (Thousand Barrels per Day)',\n",
    "        'grossRunsP9' : 'Weekly PADD 9 Gross Runs  (Thousand Barrels per Day)',\n",
    "        'feedstockRunsP9' : 'Weekly PADD 9 Feedstock Runs  (Thousand Barrels per Day)',\n",
    "        'crudeStocksP9' : 'Weekly PADD 9 Crude Stocks  (Thousand Barrels)',\n",
    "        'crudeImportsP9' : 'Weekly PADD 9 Crude Imports  (Thousand Barrels per Day)',\n",
    "        # 'crudeOriginalAdjustment' : 'Weekly US Crude Original Adjustment  (Thousand Barrels per Day)',\n",
    "        'crudeStocksP2E' : 'Weekly PADD 2 East Coast Crude Stocks  (Thousand Barrels)',\n",
    "        }\n",
    "    wps_df = pd.DataFrame(wps_dicts.items(), columns=['id','name'])\n",
    "\n",
    "    df = df[wps_dicts.keys()]\n",
    "    df = df.reset_index()\n",
    "    df = pd.melt(df, id_vars=['period'], value_vars=wps_dicts.keys())\n",
    "    df = pd.merge(df, wps_df, on='id', how='left')\n",
    "    return df\n",
    "\n",
    "def generate_additional_tickers(df):\n",
    "    df = df.copy()\n",
    "    dff = generate_additional_calculation(df)\n",
    "    df = pd.concat([df, dff])\n",
    "    return df\n",
    "\n",
    "def generate_adjustment_factor(raw):\n",
    "    df = raw.copy()\n",
    "    ids = ['WCRSTUS1','WCRFPUS2','WCEIMUS2','WCRRIUS2','WCREXUS2']\n",
    "    df = df[df['id'].isin(ids)]\n",
    "    pv = df.pivot(index='period',columns='id',values='value')\n",
    "    pv['stock_change'] = pv['WCRSTUS1'].diff() / 7\n",
    "    pv['adjustment_factor'] = (pv['WCRFPUS2'] + pv['WCEIMUS2'] - pv['WCRRIUS2'] - pv['WCREXUS2'] - pv['stock_change']) * -1\n",
    "    pv = pv.dropna(subset=['adjustment_factor'])\n",
    "    pv['adjustment_factor'] = pd.to_numeric(pv['adjustment_factor'], errors='coerce').round(0)\n",
    "    pv['adjustment_factor'] = pv['adjustment_factor'].astype(int)\n",
    "    pv['adjustment_factor'] = pv['adjustment_factor'].astype(object)\n",
    "    pv = pv[['adjustment_factor']].reset_index()\n",
    "    pv = pv.rename_axis(None, axis=1)\n",
    "    pv = pv.rename(columns={'adjustment_factor':'value'})\n",
    "    pv['name'] = 'Weekly U.S. Crude Oil Adjustment Factor  (Thousand Barrels per Day)'\n",
    "    pv['id'] = 'crudeOriginalAdjustment'\n",
    "    raw = pd.concat([raw, pv])\n",
    "    return raw\n",
    "\n",
    "def add_uom(df):\n",
    "    df = df.copy()\n",
    "    df['uom'] = 'kbd'\n",
    "    df.loc[df['name'].str.contains('stock', case=False), 'uom'] = 'kb'\n",
    "    df.loc[df['name'].str.contains('percent', case=False), 'uom'] = 'pct'    \n",
    "    df.loc[df['name'].str.contains('feedstock', case=False), 'uom'] = 'kbd'\n",
    "    return df\n",
    "\n",
    "def filter_data(df):\n",
    "    df = df.copy()\n",
    "    mapping = list(production_mapping.keys())\n",
    "    df = df[df['id'].isin(mapping)]\n",
    "    return df\n",
    "\n",
    "def reorder_columns(df):\n",
    "    df = df.copy()\n",
    "    #id,name,uom,period,value\n",
    "    df = df[['id','name','uom','period','value']]\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    download_raw_file()\n",
    "    sheets = read_excel_file()\n",
    "    df = parse_all_data(sheets)\n",
    "    df = generate_additional_tickers(df)\n",
    "    df = generate_adjustment_factor(df)\n",
    "    df = df[df['period'] >= '2014-12-26']\n",
    "    df = add_uom(df)\n",
    "    df = filter_data(df)\n",
    "    df = reorder_columns(df)\n",
    "    df.to_csv('./data/wps_gte_2015.csv',index=False)\n",
    "\n",
    "#if name is main, run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
